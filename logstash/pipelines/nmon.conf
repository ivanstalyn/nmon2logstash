input {
    file {
        path => ["/usr/share/logstash/pipeline/nmon/data/*"]
        mode => "read"
        codec => plain {charset => "UTF-8"}
        sincedb_path => "/usr/share/logstash/pipeline/nmon/sincedb/sincedb.txt"
        start_position => "beginning"
    }
}


filter {
    
    grok {
		break_on_match => true
        patterns_dir => ["/usr/share/logstash/pipeline/nmon/patterns/"]
		match =>  { "message" => [
                        "%{TIMESTAMP_ISO8601:registrofecha},%{WORD:muestra},%{WORD:server},%{WORD:seccion},%{WORD:metricatipo},(?<metricasubtipo>[^|{1}]+),%{NUMBER:valor}",
                        "%{TIMESTAMP_ISO8601:registrofecha},%{WORD:muestra},%{WORD:server},%{WORD:seccion},%{WORD:metricatipo},(?<metricasubtipo>[^|{1}]+),%{WORD:dato}"
                    ]
                } 
                
    }

    mutate {
        lowercase => [ "server", "seccion" ]
        copy => { "registrofecha" => "ftemp" }
    }

    mutate {
        split => ["ftemp", "T"]
	    add_field => ["[@metadata][fecha]", "%{[ftemp][0]}"]
    }

    if [valor] {
        mutate {
            convert => {
            "valor" => "float"
            }
        }
	}

    date {
	    match => [ "registrofecha", "ISO8601"]
    }

    mutate {
		remove_field => ["registrofecha","host", "path", "message", "ftemp"]
    }

    if "_grokparsefailure" in [tags] {
	    drop {}
	}

}

output {
    elasticsearch {
        hosts => ["elasticsearch.podman.ec:9200"]
        index => "nmon_%{server}_%{[@metadata][fecha]}"
    }
}
